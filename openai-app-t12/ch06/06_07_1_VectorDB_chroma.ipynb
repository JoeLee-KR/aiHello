{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os, sys, shutil\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../../_apikeys.env\")\n",
    "api_key = os.getenv(\"DoogieOpenaiKey\")\n",
    "os.environ['OPENAI_API_KEY'] = api_key"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#\n",
    "# Step 1-1: get test documents\n",
    "#\n",
    "import urllib.request\n",
    "\n",
    "urllib.request.urlretrieve(\"https://github.com/chatgpt-kr/openai-api-tutorial/raw/main/ch06/2023_%EB%B6%81%ED%95%9C%EC%9D%B8%EA%B6%8C%EB%B3%B4%EA%B3%A0%EC%84%9C.pdf\", filename=\"06_07_test.pdf\")"
   ],
   "id": "7dbde76dc7a2f13c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#\n",
    "# Step 1-2: load and split documents\n",
    "# 17~20 sec\n",
    "#\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader( \"06_07_test.pdf\" )\n",
    "pages = loader.load_and_split()  # about 17s\n",
    "#pages = loader.load()  # about 16s, include empty page\n"
   ],
   "id": "97349a1e9c9a70cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print( 'type loader,pages:', type(loader), type(pages) )\n",
    "print( 'type pages[0]s:', type(pages[0]), type(pages[0].page_content))\n",
    "print( 'size/len loader,pages:', sys.getsizeof(loader), len(pages) )\n",
    "print( 'size/len pages[0]s:', sys.getsizeof(pages[0]), len(pages[0].page_content) )\n",
    "print( 'pages Max:', max(len(apage.page_content) for apage in pages ) )\n",
    "print( 'pages Min:', min(len(apage.page_content) for apage in pages ) )\n",
    "print( 'pages Sum:', sum(len(apage.page_content) for apage in pages ) )\n",
    "print( '#of chunks:', len(pages) )\n",
    "print( 'Chunk Avg:', sum(len(apage.page_content) for apage in pages ) / len(pages) )"
   ],
   "id": "4642e6abb2a5cd14",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#print( pages[0] )\n",
    "#print( pages[0].page_content)\n",
    "#print( \"example:\", pages[6].page_content[:50] )\n",
    "#print( pages[442].page_content )"
   ],
   "id": "95f7bb8ba1bcbccd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Step 2: case1:\n",
    "# RecursiveCharacterTextSpilter를 사용함\n",
    "#\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "textSplitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size= 1000,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "splitedDocs = textSplitter.split_documents( pages )"
   ],
   "id": "3d2bc0cdf6ef0133",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print( 'type split,splitDocs:', type(textSplitter), type(splitedDocs) )\n",
    "print( 'type splitedDocs[0]s:', type(splitedDocs[0]), type(splitedDocs[0].page_content) )\n",
    "print( 'size/len split,splitDocs:', sys.getsizeof(textSplitter), len(splitedDocs) )\n",
    "print( 'size/len splitedDocs[0]s:', sys.getsizeof(splitedDocs[0]), len(splitedDocs[0].page_content) )\n",
    "print( 'splitedDocs Max:', max(len(apage.page_content) for apage in splitedDocs ) )\n",
    "print( 'splitedDocs Min:', min(len(apage.page_content) for apage in splitedDocs ) )\n",
    "print( 'splitedDocs Sum:', sum(len(apage.page_content) for apage in splitedDocs ) )\n",
    "print( '#of chunks:', len(splitedDocs) )\n",
    "print( 'Chunk Avg:', sum(len(apage.page_content) for apage in splitedDocs ) / len(splitedDocs) )"
   ],
   "id": "aecff3c27907fced",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#\n",
    "# DONT USE THIS CODE !!! use Step3-2 Code !!!\n",
    "# Step3-1: Loading splitedDocs to chroma\n",
    "# Error case: \"Requested 367501 tokens, max 300000 tokens per request\"\n",
    "#\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "#from langchain.vectorstores import Chroma\n",
    "\n",
    "myEmbeddings = OpenAIEmbeddings()\n",
    "print(\"current OpenAIEmbeddings().model=\", myEmbeddings.model)\n",
    "myEmbeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "print(\"current OpenAIEmbeddings().model=\", myEmbeddings.model)\n",
    "\n",
    "persist_dir = \"../localdb/my_chroma_db_01\"\n",
    "myCollectionName = \"my_collection\"\n",
    "\n",
    "vdb = Chroma.from_documents(\n",
    "    splitedDocs,\n",
    "    myEmbeddings\n",
    ")\n",
    "print(\"vdb적재문서수=\", vdb._collection.count())\n"
   ],
   "id": "be42d26e0ae31da0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#\n",
    "# Step3-2: using package 'langchain_openai', not 'OpenAIEmbeddings'\n",
    "#          from langchain.embeddings import OpenAIEmbeddings\n",
    "#          'langchain.embeddings' deprecated, use 'langchain_openai'\n",
    "#\n",
    "#from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "#from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "myEmbeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "print(\"current OpenAIEmbeddings().model=\", myEmbeddings.model)\n",
    "\n",
    "persist_dir = \"../localdb/my_chroma_db_01\"\n",
    "myCollectionName = \"my_collection\"\n"
   ],
   "id": "3aa52a7a37b35b92",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#\n",
    "# Step3-3: Loading splitedDocs to chroma\n",
    "# chatgpt guide, use this code\n",
    "#\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "def process_in_batches(documents, batch_size=100, reset_db=True):\n",
    "    global vdb\n",
    "\n",
    "    # -- 집어 넣을 문서 확인 --\n",
    "    splitedDocsLen = len(splitedDocs)\n",
    "    print(\">> ready to insert splitedDocs, len = \", splitedDocsLen)\n",
    "\n",
    "    if splitedDocsLen == 0:\n",
    "        print(\"splitedDocs가 비어있습니다.\")\n",
    "        return 0\n",
    "\n",
    "    # -- 문서 크기를 batch_size로 나누어 확인하기\n",
    "    batchCount = splitedDocsLen // batch_size\n",
    "    if splitedDocsLen % batch_size > 0:\n",
    "        batchCount += 1\n",
    "    print(\">> batchsize is \", batch_size, \"and batchCount:\", batchCount)\n",
    "\n",
    "    # -- 문서를 batch_size로 잘라서 집어 넣기\n",
    "    for i, batch in enumerate(range(0, splitedDocsLen, batch_size)):\n",
    "        print(\">>\", i, \"th batch, \", batch, \"..\", batch + batch_size - 1, end=\"\")\n",
    "        batchDocs = splitedDocs[batch:batch + batch_size]\n",
    "        vdb.add_documents(batchDocs)\n",
    "        print(\" ++ added batchDocs len:\", len(batchDocs))\n",
    "    print(\">> vdb size:\", len( vdb.get()[\"ids\"] ))\n",
    "\n",
    "def clear_before_addDoc():\n",
    "    global vdb\n",
    "    all_ids = vdb.get()[\"ids\"]\n",
    "\n",
    "    if ( len(all_ids) == 0 ):\n",
    "        print(\">> vdb size = 0 이므로 collection delete 하지 않음.\")\n",
    "        return\n",
    "\n",
    "    # 컬렉션 내부 데이터 전체 삭제\n",
    "    print(f\">> vdb size = {len(all_ids)}, 벡터 컬렉션 데이터 삭제 시작...\", end=\"\")\n",
    "    try:\n",
    "        vdb._collection.delete(ids=all_ids)\n",
    "        print(\"++벡터 컬렉션 데이터 삭제 완료.\")\n",
    "    except Exception as e:\n",
    "        print(\"++벡터 컬렉션 삭제 실패:\", e)\n",
    "    print(\">> vdb size = \", len( vdb.get()[\"ids\"] ) )\n",
    "\n",
    "# -- main body\n",
    "\n",
    "\n",
    "# --- 기존(또는 새) 컬렉션 열기(임베딩 함수 전달) ---\n",
    "vdb = Chroma(\n",
    "    embedding_function=myEmbeddings,\n",
    "    persist_directory=persist_dir,\n",
    "    collection_name=myCollectionName\n",
    ")\n",
    "\n",
    "print(\"[START] vdb 크기=\", len( vdb.get()[\"ids\"] ) )\n",
    "print(\">>Persist Dir:\", persist_dir)\n",
    "print(\">>myCollectionName:\", myCollectionName)\n",
    "\n",
    "clear_before_addDoc()\n",
    "process_in_batches(splitedDocs, 100, True)\n",
    "\n",
    "#print(\"vdb적재문서수=\", vdb._collection.count())\n",
    "print(\"[END] vdb 크기=\", len( vdb.get()[\"ids\"] ) )"
   ],
   "id": "f44034fab4f9e84d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#\n",
    "# Step3-4: Use splitedDocs at chroma, already Chroma Data\n",
    "#     only need: openAI API connection\n",
    "#                myEmbeddings for Chroma\n",
    "#\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "vdb = Chroma(\n",
    "    embedding_function=myEmbeddings,\n",
    "    persist_directory=persist_dir,\n",
    "    collection_name=myCollectionName\n",
    ")\n",
    "\n",
    "print(\">>Persist Dir:\", persist_dir)\n",
    "print(\">>myCollectionName:\", myCollectionName)\n",
    "print(\">>vdb 크기=\", len( vdb.get()[\"ids\"] ) )"
   ],
   "id": "5b04dca9e858e20e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "ㅊ",
   "id": "83657a1ddcd536cc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for resultDoc in resultDocs:\n",
    "    print('---' * 10)\n",
    "    print(resultDoc.metadata.get(\"page_label\"), resultDoc.page_content[:100] )\n"
   ],
   "id": "98091f048fcc221d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#\n",
    "# 4-2: other handle of ChromaDB\n",
    "#\n",
    "vdb2 = Chroma(\n",
    "    persist_directory=persist_dir,\n",
    "    embedding_function=myEmbeddings,\n",
    "    collection_name=myCollectionName\n",
    ")\n",
    "print('문서의 수:', vdb2._collection.count())\n",
    "print( type(vdb), type(vdb2) )\n",
    "\n",
    "question = '북한의 교육과정'\n",
    "resultDocs = vdb2.similarity_search(question)\n",
    "print('유사문서수:', len(resultDocs))\n",
    "print( type(resultDocs), type(resultDocs[0]), type(resultDocs[0].page_content) )\n",
    "\n",
    "for resultDoc in resultDocs:\n",
    "    print('---' * 10)\n",
    "    print(resultDoc.metadata.get(\"page_label\"), resultDoc.page_content[:100] )\n"
   ],
   "id": "2ba8a45845e77b14",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print( vdb is vdb2 )\n",
    "print( vdb == vdb2 )\n",
    "print( id(vdb) == id(vdb2), id(vdb), id(vdb2) )\n",
    "print( vdb._collection.id == vdb2._collection.id, vdb._collection.id, vdb2._collection.id )\n",
    "print('------')\n",
    "print( type(vdb), type(db_from_file) )\n",
    "print( type(vdb._client), type(db_from_file._client))\n",
    "\n",
    "print('------')\n",
    "print(vdb._collection.name, db_from_file._collection.name)\n",
    "print(vdb._collection.name == db_from_file._collection.name) # True\n",
    "print(vdb._client.list_collections() )\n",
    "#print(vdb._client._settings.chroma_db_impl)\n",
    "#print(db_from_file._client._settings.chroma_db_impl)# 둘 다 'duckdb+parquet'\n",
    "#print(vdb._client._settings.persist_directory == db_from_file._client._settings.persist_directory)  # True\n"
   ],
   "id": "32f193101959f374",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#\n",
    "# 4-3\n",
    "# find top 3, print similarity score\n",
    "# List[Document] -> docs[0].metadata, docs[0].page_content\n",
    "# List[Tuple[Document, float]] -> docs[0][0].metadata, docs[0][1]\n",
    "question = '북한의 교육과정'\n",
    "resultDocs = vdb2.similarity_search_with_relevance_scores(question, k=3)\n",
    "print('유사문서수:', len(resultDocs))\n",
    "print( type(resultDocs), type(resultDocs[0]) )\n",
    "print( type(resultDocs[0][0]), type(resultDocs[0][0].page_content) )\n",
    "print( type(resultDocs[0][1]), resultDocs[0][1] )\n",
    "\n",
    "for resultDoc in resultDocs:\n",
    "    print('---' * 10)\n",
    "    print(resultDoc[1], resultDoc[0].page_content[:100])\n",
    "\n",
    "for resultDoc, score in resultDocs:\n",
    "    print('---' * 10)\n",
    "    print(score, len(resultDoc.page_content) )"
   ],
   "id": "fb9801241b4ffa98",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
