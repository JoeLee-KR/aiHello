import streamlit as st
from openai import OpenAI, api_key

import os
import io
import base64
from PIL import Image
from dotenv import load_dotenv

load_dotenv("../../_apikeys.env")
OPENAI_API_KEY = os.getenv("Doogie.2ndKey")
OpenAIclient = OpenAI( api_key = OPENAI_API_KEY )

def GPT4Vcall(urlPrompt):
    # "ì´ ì´ë¯¸ì§€ì— ëŒ€í•´ì„œ ì•„ì£¼ ìì„¸íˆ ë¬˜ì‚¬í•´ì¤˜"
    response = OpenAIclient.chat.completions.create(
    #model="gpt-4-vision-preview",
    model="gpt-4-turbo",
    messages=[
        {
        "role": "user",
        "content": [
            {"type": "text", "text": "ì´ ì´ë¯¸ì§€ì— ëŒ€í•´ì„œ ì•„ì£¼ ìì„¸íˆ ë¬˜ì‚¬í•´ì¤˜"},
            {
            "type": "image_url",
            "image_url": {
                "url": urlPrompt,
            },
            },
        ],
        }
    ],
    max_tokens=1024,
    )
    print( response )
    total_bill = (response.usage.completion_tokens * 30 + response.usage.prompt_tokens * 10) / 1000000
    sumbill = f"""
            Tokens, total:{response.usage.total_tokens}, \
            prompt:{response.usage.prompt_tokens}, \
            completion: {response.usage.completion_tokens} \
            and, Total Bill: {total_bill} USD...
        """
    st.text( sumbill)
    #return response.choices[0].message.content
    return response

# TTS
def TTScall(response):
    # TTSë¥¼ í™œìš©í•˜ì—¬ Textë¥¼ ìŒì„±ìœ¼ë¡œ ë§Œë“  objectì„ íŒŒì¼ë¡œ ì €ì¥.
    with OpenAIclient.audio.speech.with_streaming_response.create(
        model='tts-1',
        voice='shimmer',
        input=response,
    ) as xresponse:
        filename = "joe_tmp.mp3"
        xresponse.stream_to_file(filename)

    # ì €ì¥í•œ ìŒì„±íŒŒì¼ì„ streamli webappì—ì„œ ìë™ ì¬ìƒ
    with open(filename, "rb") as f:
        data = f.read()
        b64 = base64.b64encode(data).decode()
        # HTML ë¬¸ë²•ì„ ì‚¬ìš©í•˜ì—¬ ìë™ìœ¼ë¡œ ìŒì›ì„ ì¬ìƒí•˜ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•˜ì—¬
        # streamlit ì•ˆì—ì„œ HTML ë¬¸ë²• êµ¬í˜„ì— ì‚¬ìš©ë˜ëŠ” st.markdown() ì„ í™œìš©í•˜ì—¬ ì‹¤í–‰ì„ í•©ë‹ˆë‹¤.
        md = f"""
            <audio autoplay="True">
            <source src="data:audio/mp3;base64,{b64}" type="audio/mp3">
            </audio>
            """
        st.markdown(md, unsafe_allow_html=True, )
    # í´ë”ì— ë‚¨ì§€ ì•Šë„ë¡ íŒŒì¼ ì‚­ì œ
    # os.remove(filename)

def main():
    st.title("ğŸ’¬ ì´ë¯¸ì§€ë¥¼ í•´ì„¤í•´ë“œë¦½ë‹ˆë‹¤.")

    # ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œ
    img_file_handle = st.file_uploader('Upload a PNG image', type='png')

    if img_file_handle is not None:

        image = Image.open(img_file_handle)

        # ì—…ë¡œë“œí•œ ì´ë¯¸ì§€ë¥¼ í™”ë©´ì— ì¶œë ¥
        st.image(image, caption='Uploaded Image.', use_container_width=True)

        # ì´ë¯¸ì§€ => ë°”ì´íŠ¸ ë²„í¼ë¡œ ë³€í™˜
        bytebuffered = io.BytesIO()
        image.save(bytebuffered, format="PNG")
        # ë°”ì´íŠ¸ ë²„í¼ => Base64 ì¸ì½”ë”© ë°”ì´íŠ¸ ë¬¸ìì—´ë¡œ ë³€í™˜
        img_base64 = base64.b64encode(bytebuffered.getvalue())
        # Base64 ì¸ì½”ë”© ë°”ì´íŠ¸ ë¬¸ìì—´ => UTF-8 ë¬¸ìì—´ë¡œ ë””ì½”ë”©
        img_base64_str = img_base64.decode('utf-8')

        # GPT-4Vì—ì„œ ì…ë ¥ë°›ì„ ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ë³€í™˜
        # ì˜ˆì‹œ ì°¸ê³ : https://platform.openai.com/docs/guides/vision/uploading-base-64-encoded-images
        image4gpt = f"data:image/jpeg;base64,{img_base64_str}"

        # GPT4Vê°€ ì´ë¯¸ì§€ì— ëŒ€í•œ ì„¤ëª…ì„ ë°˜í™˜í•˜ê³  ì´ë¥¼ st.info()ë¡œ ì¶œë ¥.
        responseObject = GPT4Vcall(image4gpt)
        st.info(responseObject.choices[0].message.content)

        # ì´ë¯¸ì§€ì— ëŒ€í•œ ì„¤ëª…ì„ ìŒì„±ìœ¼ë¡œ ë³€í™˜.
        TTScall(responseObject.choices[0].message.content)
if __name__=="__main__":
    main()
